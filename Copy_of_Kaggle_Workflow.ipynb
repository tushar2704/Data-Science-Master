{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tushar2704/Data-Science-Master/blob/main/Copy_of_Kaggle_Workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16TYEg-mzgBC"
      },
      "source": [
        "## Unleashing the mystery of Kaggle\n",
        "- How does it all work?\n",
        "- Feature Engineering\n",
        "- Parameter Tuning\n",
        "- Ensembling & Stacking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d7GEIYOzuGi"
      },
      "source": [
        "## How does it all work - Should I trust the public leaderboard?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D0BrbKfz1Y4"
      },
      "source": [
        "- Each Kaggle competition has public and private leaderboard. Public leaderboard only uses part of the test dataset to determine the score and the private leaderboard will evaluated using the other part at the end of the competition.\n",
        "- You can find how Kaggle calculate the public and private leaderboard [here](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/leaderboard).\n",
        "- If the competition has a large training set and a relatively small public test set compared to private test set, you can easily overfit the public test set. In this case, you **should not** trust the public leaderboard. \n",
        "- If the traing set and test set are collected from different time frames, you **must** trust the public leaderboard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnlL8ysdz7F7"
      },
      "source": [
        "![img](https://s3.amazonaws.com/nycdsabt01/s2-4.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "272XAYvu0BtI"
      },
      "source": [
        "### CV or LB?\n",
        "- **TRUST YOUR CV!**\n",
        "- Typical question on smaller datasets: \n",
        " - “I’m doing proper cross-validation and see improvements on my CV score, but public leaderboard is so random and does not correlate at all!”\n",
        "- Top kagglers’ pick most of the time:\n",
        " - Final Submission = $X*CV + (1-X)*LB$, typically $X=0.5$ is OK.\n",
        "- Trusting CV is a hard thing to do"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgaUQq-C0jK3"
      },
      "source": [
        "## Step 1: Preprocess\n",
        "- We will be using the [housing price prediction](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) Kaggle competition to illustrate the workflow. With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n",
        "- To work with Kaggle competition in Google Colab, you need to have a Kaggle account and then click the avatar on the top right corner -> My Account -> Create New API Token and it will download a `kaggle.json` file. \n",
        "- Open the file and copy & paste the username and password to the following code chunk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Cs5XAOorFPu"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"xxxxxxx\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"xxxxxxxxxxxxxxxxxxx\" # key from the json file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGO-weLKjNig"
      },
      "source": [
        "- Using API to download the dataset directly from Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai5DUNBvJtEU"
      },
      "source": [
        "!kaggle competitions download -c house-prices-advanced-regression-techniques"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObvcOoPHrYbW"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxHrRB6Br8v2"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOKnPw64jhjz"
      },
      "source": [
        "- Google colab is running [Dokcer](https://www.youtube.com/watch?v=t9YuqwGYUUg&feature=youtu.be) containers behind the scene so that means you will lose your data if you disconnect from the server. \n",
        "- A easier solution is to mount your google drive to the docker container. You can also save the preprocessed the data files to avoid running the same code each time.\n",
        "- Run the following cell to mount your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeBdjpcbsALx"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbofyRHwnWXF"
      },
      "source": [
        "- Run the following code chunk if you want to use your own drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWiwom4imrGr"
      },
      "source": [
        "# import os\n",
        "# os.chdir('/content/drive/My Drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK-96JxeNSCL"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_columns', 100)\n",
        "\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR4-xyZMsH6a"
      },
      "source": [
        "# Save the 'Id' column\n",
        "train_ID = train_df['Id']\n",
        "test_ID = test_df['Id']\n",
        "\n",
        "# Now drop the 'Id' colum since we can not use it as a feature to train our model.\n",
        "train_df.drop(\"Id\", axis = 1, inplace = True)\n",
        "test_df.drop(\"Id\", axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMEX6kFgNX8W"
      },
      "source": [
        "y_train = train_df['SalePrice']\n",
        "X_train = train_df.drop('SalePrice', axis=1)\n",
        "X_test = test_df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSn00QkENlpq"
      },
      "source": [
        "- Delete the dataframes that you do not need anymore to save computer RAM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5syrdqxNm_Q"
      },
      "source": [
        "del train_df, test_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNS1WSYaNo9I"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y2msHo9NtXm"
      },
      "source": [
        "- Combine training and test dataframes before feature engineering.\n",
        "- **This is not always the correct way.**\n",
        " - For categorial features, this is fine because you want to avoid having new categories in the test set, which will cause different dimensions after dummify the data set.\n",
        " - If you want to perform any transformation (normalization, standardization, etc) on the numerical features, you should **[fit on the training set and transform on the test set.](https://stats.stackexchange.com/a/174865)**\n",
        " - It also applys to how you perform cross-validation. See Chapter 7.10.2 of [ESLR](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIr-Sc6UNt3g"
      },
      "source": [
        "all_data = pd.concat([X_train, X_test], ignore_index=True)\n",
        "all_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQNtmofnPG4Q"
      },
      "source": [
        "## Step 2: Feature Engineering - most creative aspect of data science"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsGLPmnbPbrc"
      },
      "source": [
        "### Categorical  features\n",
        "- Nearly always need some treatment\n",
        "- High cardinality can create very sparse data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CVZyN-nPhkp"
      },
      "source": [
        "#### One-hot encoding\n",
        "- One-of-K encoding on an array of length K\n",
        "- Basic method: used with most linear algorithm\n",
        "- Drop first column avoids collinearity\n",
        " - encoding gender as two variables, **is_male** and **is_female**, produces two features which are perfectly negatively correlated\n",
        "- Encode categories appearing 3+ times\n",
        " - Reduce training feature space with no loss of info."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z47-9eiNXZKw"
      },
      "source": [
        "for c in all_data.columns:\n",
        "    if all_data[c].dtype == 'object':\n",
        "        print(c, len(all_data[c].value_counts()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFPWUwjzXZOT"
      },
      "source": [
        "one_hot_df = pd.get_dummies(all_data, drop_first=True, dummy_na=True)\n",
        "one_hot_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12i1Qk_476GV"
      },
      "source": [
        "- To view the quick documentation of the function, just put `??` in front of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkFEgZhdFrjl"
      },
      "source": [
        "??pd.get_dummies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmrcsJsCPhq6"
      },
      "source": [
        "#### Label encoding\n",
        "- Give every categorial variable a unique numerical ID\n",
        "- Useful for non-linear tree-based algorithm\n",
        "- Does not increase dimensionality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaynhWX9ujR4"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_df = all_data.copy()\n",
        "\n",
        "for c in label_df.columns:\n",
        "    if label_df[c].dtype == 'object':\n",
        "        le = LabelEncoder()\n",
        "        # Need to convert the column type to string in order to encode missing values\n",
        "        label_df[c] = le.fit_transform(label_df[c].astype(str))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq0QUC4Aumgm"
      },
      "source": [
        "label_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IcW0pbkPhtk"
      },
      "source": [
        "### Ordinal Features\n",
        "\n",
        "- Label Count encoding is good in general, however, some of the features are ordinal in nature.\n",
        "- For example, we usually consider Excellent > Good > Average/Typical > Fair > Poor\n",
        "- We can construct a dictionary like the following and map it to those columns:\n",
        "  ```python\n",
        "  {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa':2, 'Po':1}\n",
        "  ```\n",
        " \n",
        "- You need a different dictionary for columns with different levels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy0WKUB1urla"
      },
      "source": [
        "ord_cols = ['ExterQual', 'ExterCond','BsmtCond','HeatingQC', 'KitchenQual', \n",
        "           'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']\n",
        "ord_dic = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa':2, 'Po':1}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fenxoIuvLVC"
      },
      "source": [
        "ord_df = X_train.copy()\n",
        "\n",
        "for col in ord_cols:\n",
        "    ord_df[col] = ord_df[col].map(lambda x: ord_dic.get(x, 0))\n",
        "ord_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnnVBMHYv0cq"
      },
      "source": [
        "#### Interactions\n",
        "- If interactions are natural for a problem - ML only does approximations! => sub-optimal\n",
        " - Start from interactions that make sense intuitively. \n",
        " - Winners usually find something that most people struggle to see in data. **Not many people look at the data at all!**\n",
        " \n",
        "|  GarageCond |   GarageType   | GarageCond * GarageType  |\n",
        "| ------------|:--------------:| -----:|\n",
        "|  Ex  | 2Types | Ex * 2Types |\n",
        "|  Ex  | CarPort| Ex * CarPort|\n",
        "|  TA  | Basement| TA * Basement|\n",
        "|  Fa  | BuiltIn | Fa * BuiltIn |\n",
        " \n",
        " \n",
        "- Test your method with all explicitly created possible 2-way interactions if you have enough computing power\n",
        "- This is especially useful when dealing with **anonymous data** (column name unknown)\n",
        "- If 2-way interactions help – go even further (3-way, 4-way, ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOzidhiFsFOb"
      },
      "source": [
        "**Dealing with NA's depends on situation. NA itself is an information unit! Usually separate category is enough.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xahRIlN-v623"
      },
      "source": [
        "### Numerical features\n",
        "Feature transformations to consider:\n",
        "- Scaling - min/max, N(0,1), root/power scaling, log scaling, Box-Cox, quantiles.\n",
        "- Rounding (too much precision might be noise!)\n",
        "- Interactions {+,-,*,/}\n",
        " - Since area related features are very important to determine house prices, we can add one more feature which is the total area of basement, first and second floor areas of each house\n",
        " - `all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']`\n",
        "- **Tree methods are almost invariant to scaling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCaq8iM00QPl"
      },
      "source": [
        "## Step 3: Parameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_-Dnohm0TG1"
      },
      "source": [
        "#### Basic approach: apply grid search on all parameter space\n",
        "- Zero effort and no supervision\n",
        "- Enormous parameter space\n",
        "- Very time consuming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yIGponr0TJi"
      },
      "source": [
        "#### Expert approach: experience + intuition + resources at hand\n",
        "1. Pick one set of parameters from the Kaggle kernel or the golden parameter you used in the previous competition\n",
        "2. Start with the parameter that doesn't affect the others too much\n",
        " - i.e. learning rate $\\eta $ in boosting method doesn't influence other parameter tuning (from my experience)\n",
        " - `max_depth`, `min_samples_split` and `min_samples_leaf` in random forest are highly correlated with each other\n",
        "3. Iteratively tuning the features that control overfitting/underfitting\n",
        " - If it helps on CV, try to tune it as much as possible. Stop after CV score converges.\n",
        " - You can use public leaderboard as your K+1 fold to further prove it.\n",
        "4. Go back to step 2 and stop when you are satisfied with the result and won't regret not working harder.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIG-OEoj0TMA"
      },
      "source": [
        "#### [Bayesian optimization method](https://github.com/fmfn/BayesianOptimization/blob/master/examples/visualization.ipynb): trade-off between expert and grid search approach\n",
        "- Zero effort and no supervision\n",
        "- Grid space reduced on previous iteration's results (mimic expert decisions)\n",
        "- Time consuming (still)\n",
        "- Easy to integrate with sklearn cross validation function. See [examples](https://github.com/fmfn/BayesianOptimization/blob/master/examples/sklearn_example.py) here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4leQr_7Ag-t"
      },
      "source": [
        "#### Golden rule: finding optimal configuration rarely is a good time investment!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6FFlEy6AmMU"
      },
      "source": [
        "## Step 4: Ensemble & Stacking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD4EwCvTAmR4"
      },
      "source": [
        "### [Ensembling by voting](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier)\n",
        "```\n",
        "1111111100 = 80% accuracy \n",
        "0111011101 = 70% accuracy \n",
        "1000101111 = 60% accuracy\n",
        "```\n",
        "**Majority Vote**\n",
        "```\n",
        "1111111101 = 90% accuracy\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_jG_8yaAt6z"
      },
      "source": [
        "### Ensembling by averaging\n",
        "- Let’s say we have N predictions from N different models: $y_1, y_2, ... , y_N$\n",
        "- We want to make a single prediction using weighted average: $\\beta_1*y_1+\\beta_2*y_2+...+\\beta_N*y_N$\n",
        "- How do we find the best beta cofficients?\n",
        "- Very common mistake to select weights based on leaderboard feedback\n",
        " - **inefficient & prone to leaderboard overfitting**\n",
        "- Solve the problem using CV predictions with optimization algorithms \n",
        " - $optim(\\beta_1*y_1+\\beta_2*y_2+...+\\beta_N*y_N)$ with starting weights $\\beta_i=1/N$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHwlHg70BMjz"
      },
      "source": [
        "### Stacked Generalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkVuwX1nBMpw"
      },
      "source": [
        "The procedure for a 5 fold stacking may be described as follows:\n",
        "\n",
        "1. Split the total training set into two disjoint sets (here train and holdout)\n",
        "\n",
        "2. Train several base models on the first part (train)\n",
        "\n",
        "3. Predict these base models on the second part (holdout)\n",
        "\n",
        "4. Repeat step 1-3 five times and use the holdout predictions as the inputs, and the correct responses (target variable) as the outputs to train a higher level learner called meta-model.\n",
        "\n",
        "\n",
        "- For the test set, we could either average the predictions of all base models on the test data or refit the model using the whole training set and then predict. Generally speaking, either way is fine because the test set hasn't seen the training set.\n",
        "- If we ran 10 models using the same procedure, our meta model will have 10 input features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJsUXSwVBS9Y"
      },
      "source": [
        "![img](https://s3.amazonaws.com/nycdsabt01/stacking.jpg)\n",
        "\n",
        "Borrowed from [Faron](https://www.kaggle.com/getting-started/18153#post103381)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMdGAmxaBVqC"
      },
      "source": [
        "- As a quick note, one should try a few diverse models. To my experience, a good stacking solution is often composed of at least:\n",
        " - 2 or 3 GBMs/XGBs/LightGBMs (one with low depth, one with medium and one with high)\n",
        " - 1 or 2 Random Forests (again as diverse as possible–one low depth, one high)\n",
        " - 1 linear model**!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uaXDeqKATDj"
      },
      "source": [
        "- Download helper Python scripts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPWDoPGo9Feh"
      },
      "source": [
        "!wget https://gist.githubusercontent.com/hellozeyu/12f669f6a2f0ca4e228ed783c3937cfd/raw/5cfc1e6269bc6dc5b2e676c9970f6c95c4339ca4/preprocess.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlCtqWfM-RXN"
      },
      "source": [
        "!wget https://gist.githubusercontent.com/hellozeyu/c0183dc498841f3a913284b8aac42c35/raw/b84cee92a97097683c9ea846e88071e4f107f7d5/stacking.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aStBjffBwFaD"
      },
      "source": [
        "from sklearn.linear_model import ElasticNet, LinearRegression as lr\n",
        "from sklearn.ensemble import GradientBoostingRegressor as gbr, RandomForestRegressor as rfr\n",
        "from preprocess import impute # impute is a helper function defined under preprocess.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHKb409KsSK1"
      },
      "source": [
        "- Impute all the missing values of the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIXuarOsBZLI"
      },
      "source": [
        "all_data = impute(all_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HKQ4gAUBcSv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "bc62f321-1c37-4f4a-ac60-3344dfa9f62c"
      },
      "source": [
        "all_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Condition1</th>\n",
              "      <th>Condition2</th>\n",
              "      <th>BldgType</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>RoofMatl</th>\n",
              "      <th>Exterior1st</th>\n",
              "      <th>Exterior2nd</th>\n",
              "      <th>MasVnrType</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>ExterQual</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtCond</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Heating</th>\n",
              "      <th>HeatingQC</th>\n",
              "      <th>CentralAir</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Functional</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>FireplaceQu</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageQual</th>\n",
              "      <th>GarageCond</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>TotalSF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>None</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>196.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>706.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>856.0</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>8</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2.0</td>\n",
              "      <td>548.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>2566.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>None</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Veenker</td>\n",
              "      <td>Feedr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>978.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0.0</td>\n",
              "      <td>284.0</td>\n",
              "      <td>1262.0</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>2524.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>None</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>162.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Mn</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>486.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0.0</td>\n",
              "      <td>434.0</td>\n",
              "      <td>920.0</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2.0</td>\n",
              "      <td>608.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>2706.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>None</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>Wd Shng</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>BrkTil</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>216.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0.0</td>\n",
              "      <td>540.0</td>\n",
              "      <td>756.0</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>7</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>3.0</td>\n",
              "      <td>642.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>2473.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>None</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NoRidge</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>350.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Av</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>655.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0.0</td>\n",
              "      <td>490.0</td>\n",
              "      <td>1145.0</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>9</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>3.0</td>\n",
              "      <td>836.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>3343.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape LandContour  \\\n",
              "0         60       RL         65.0     8450   Pave  None      Reg         Lvl   \n",
              "1         20       RL         80.0     9600   Pave  None      Reg         Lvl   \n",
              "2         60       RL         68.0    11250   Pave  None      IR1         Lvl   \n",
              "3         70       RL         60.0     9550   Pave  None      IR1         Lvl   \n",
              "4         60       RL         84.0    14260   Pave  None      IR1         Lvl   \n",
              "\n",
              "  LotConfig LandSlope Neighborhood Condition1 Condition2 BldgType HouseStyle  \\\n",
              "0    Inside       Gtl      CollgCr       Norm       Norm     1Fam     2Story   \n",
              "1       FR2       Gtl      Veenker      Feedr       Norm     1Fam     1Story   \n",
              "2    Inside       Gtl      CollgCr       Norm       Norm     1Fam     2Story   \n",
              "3    Corner       Gtl      Crawfor       Norm       Norm     1Fam     2Story   \n",
              "4       FR2       Gtl      NoRidge       Norm       Norm     1Fam     2Story   \n",
              "\n",
              "   OverallQual OverallCond  YearBuilt  YearRemodAdd RoofStyle RoofMatl  \\\n",
              "0            7           5       2003          2003     Gable  CompShg   \n",
              "1            6           8       1976          1976     Gable  CompShg   \n",
              "2            7           5       2001          2002     Gable  CompShg   \n",
              "3            7           5       1915          1970     Gable  CompShg   \n",
              "4            8           5       2000          2000     Gable  CompShg   \n",
              "\n",
              "  Exterior1st Exterior2nd MasVnrType  MasVnrArea ExterQual ExterCond  \\\n",
              "0     VinylSd     VinylSd    BrkFace       196.0        Gd        TA   \n",
              "1     MetalSd     MetalSd       None         0.0        TA        TA   \n",
              "2     VinylSd     VinylSd    BrkFace       162.0        Gd        TA   \n",
              "3     Wd Sdng     Wd Shng       None         0.0        TA        TA   \n",
              "4     VinylSd     VinylSd    BrkFace       350.0        Gd        TA   \n",
              "\n",
              "  Foundation BsmtQual BsmtCond BsmtExposure BsmtFinType1  BsmtFinSF1  \\\n",
              "0      PConc       Gd       TA           No          GLQ       706.0   \n",
              "1     CBlock       Gd       TA           Gd          ALQ       978.0   \n",
              "2      PConc       Gd       TA           Mn          GLQ       486.0   \n",
              "3     BrkTil       TA       Gd           No          ALQ       216.0   \n",
              "4      PConc       Gd       TA           Av          GLQ       655.0   \n",
              "\n",
              "  BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF Heating HeatingQC  \\\n",
              "0          Unf         0.0      150.0        856.0    GasA        Ex   \n",
              "1          Unf         0.0      284.0       1262.0    GasA        Ex   \n",
              "2          Unf         0.0      434.0        920.0    GasA        Ex   \n",
              "3          Unf         0.0      540.0        756.0    GasA        Gd   \n",
              "4          Unf         0.0      490.0       1145.0    GasA        Ex   \n",
              "\n",
              "  CentralAir Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  GrLivArea  \\\n",
              "0          Y      SBrkr       856       854             0       1710   \n",
              "1          Y      SBrkr      1262         0             0       1262   \n",
              "2          Y      SBrkr       920       866             0       1786   \n",
              "3          Y      SBrkr       961       756             0       1717   \n",
              "4          Y      SBrkr      1145      1053             0       2198   \n",
              "\n",
              "   BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  KitchenAbvGr  \\\n",
              "0           1.0           0.0         2         1             3             1   \n",
              "1           0.0           1.0         2         0             3             1   \n",
              "2           1.0           0.0         2         1             3             1   \n",
              "3           1.0           0.0         1         0             3             1   \n",
              "4           1.0           0.0         2         1             4             1   \n",
              "\n",
              "  KitchenQual  TotRmsAbvGrd Functional  Fireplaces FireplaceQu GarageType  \\\n",
              "0          Gd             8        Typ           0        None     Attchd   \n",
              "1          TA             6        Typ           1          TA     Attchd   \n",
              "2          Gd             6        Typ           1          TA     Attchd   \n",
              "3          Gd             7        Typ           1          Gd     Detchd   \n",
              "4          Gd             9        Typ           1          TA     Attchd   \n",
              "\n",
              "   GarageYrBlt GarageFinish  GarageCars  GarageArea GarageQual GarageCond  \\\n",
              "0       2003.0          RFn         2.0       548.0         TA         TA   \n",
              "1       1976.0          RFn         2.0       460.0         TA         TA   \n",
              "2       2001.0          RFn         2.0       608.0         TA         TA   \n",
              "3       1998.0          Unf         3.0       642.0         TA         TA   \n",
              "4       2000.0          RFn         3.0       836.0         TA         TA   \n",
              "\n",
              "  PavedDrive  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  \\\n",
              "0          Y           0           61              0          0            0   \n",
              "1          Y         298            0              0          0            0   \n",
              "2          Y           0           42              0          0            0   \n",
              "3          Y           0           35            272          0            0   \n",
              "4          Y         192           84              0          0            0   \n",
              "\n",
              "   PoolArea PoolQC Fence MiscFeature  MiscVal MoSold YrSold SaleType  \\\n",
              "0         0   None  None        None        0      2   2008       WD   \n",
              "1         0   None  None        None        0      5   2007       WD   \n",
              "2         0   None  None        None        0      9   2008       WD   \n",
              "3         0   None  None        None        0      2   2006       WD   \n",
              "4         0   None  None        None        0     12   2008       WD   \n",
              "\n",
              "  SaleCondition  TotalSF  \n",
              "0        Normal   2566.0  \n",
              "1        Normal   2524.0  \n",
              "2        Normal   2706.0  \n",
              "3       Abnorml   2473.0  \n",
              "4        Normal   3343.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQhXBjzVryqD"
      },
      "source": [
        "- Encode the ordinal features based on the condition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkohjMnOFb4f"
      },
      "source": [
        "for col in all_data.columns:\n",
        "    if col in ord_cols:\n",
        "        all_data[col] = all_data[col].map(lambda x: ord_dic.get(x, 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmJuBWQnsigS"
      },
      "source": [
        "- One-hot encode all the other categorical features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_vYkPwqBfnw"
      },
      "source": [
        "all_data = pd.get_dummies(all_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtwZCUA5Bfy1"
      },
      "source": [
        "train_index = len(X_train)\n",
        "X_train = all_data.iloc[:train_index, :]\n",
        "X_test = all_data.iloc[train_index:, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulg5Y6maGJUD"
      },
      "source": [
        "from stacking import stacking_regression # stacking_regression is a helper function defined under stacking.py\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEiR2JXpGM5t"
      },
      "source": [
        "def rmsle(y, y_pred):\n",
        "    return np.sqrt(mean_squared_error(np.log(y), np.log(y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzCr7muRGO3_"
      },
      "source": [
        "models = [\n",
        "    # linear model, ElasticNet = lasso + ridge\n",
        "    ElasticNet(random_state=0),\n",
        "    \n",
        "    # conservative random forst model\n",
        "    rfr(random_state=0,\n",
        "        n_estimators=1000, max_depth=6,  max_features='sqrt'),\n",
        "    \n",
        "    # aggressive random forst model\n",
        "    rfr(random_state=0, \n",
        "        n_estimators=1000, max_depth=9,  max_features='auto'),\n",
        "    \n",
        "    # conservative gbm model\n",
        "    gbr(random_state=0, learning_rate = 0.005, max_features='sqrt',\n",
        "        min_samples_leaf=15, min_samples_split=10, \n",
        "        n_estimators=3000, max_depth=3),\n",
        "    \n",
        "    # aggressive gbm model\n",
        "    gbr(random_state = 0, learning_rate = 0.01, max_features='sqrt',\n",
        "        min_samples_leaf=10, min_samples_split=5, \n",
        "        n_estimators = 1000, max_depth = 9)\n",
        "    ]\n",
        "\n",
        "meta_model = lr(normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt6q7H2LGSKl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "fb2870fe-bba9-4a85-aa14-abe3b38e2f94"
      },
      "source": [
        "%%time\n",
        "final_prediction = stacking_regression(models, meta_model, X_train, y_train, X_test,\n",
        "                               transform_target=np.log1p, transform_pred = np.expm1, \n",
        "                               metric=rmsle, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "metric: [rmsle]\n",
            "\n",
            "model 0: [ElasticNet]\n",
            "    ----\n",
            "    MEAN:   [0.19267646]\n",
            "\n",
            "model 1: [RandomForestRegressor]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/stacking.py:112: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  X_train = X_train.as_matrix()\n",
            "/content/stacking.py:113: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  X_test = X_test.as_matrix()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    ----\n",
            "    MEAN:   [0.16326278]\n",
            "\n",
            "model 2: [RandomForestRegressor]\n",
            "    ----\n",
            "    MEAN:   [0.14649338]\n",
            "\n",
            "model 3: [GradientBoostingRegressor]\n",
            "    ----\n",
            "    MEAN:   [0.12821168]\n",
            "\n",
            "model 4: [GradientBoostingRegressor]\n",
            "    ----\n",
            "    MEAN:   [0.12726764]\n",
            "\n",
            "CPU times: user 1min 9s, sys: 257 ms, total: 1min 9s\n",
            "Wall time: 1min 9s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qFg1neAIWZD"
      },
      "source": [
        "submission_df = pd.DataFrame()\n",
        "submission_df['Id'] = test_ID\n",
        "submission_df['SalePrice'] = final_prediction \n",
        "submission_df.to_csv('stacking.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E2NFgjZJkWV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d784417b-a7e6-4aa1-99dd-d3a6e8c83279"
      },
      "source": [
        "!head stacking.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Id,SalePrice\n",
            "1461,125359.34370744755\n",
            "1462,149091.1608909535\n",
            "1463,174055.74797125038\n",
            "1464,181243.35887323445\n",
            "1465,177494.68099706247\n",
            "1466,168575.32684119936\n",
            "1467,160012.00198952647\n",
            "1468,160982.77986826166\n",
            "1469,169473.06798496895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYbi1vMqHuaq"
      },
      "source": [
        "!kaggle competitions submit -c house-prices-advanced-regression-techniques -m \"stacking model\" -f stacking.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3l0KBYpHgeB"
      },
      "source": [
        "**Having more models than necessary in ensemble may hurt.**\n",
        "\n",
        "\n",
        "- Lets say we have a library of created models. Usually greedy-forward approach works well:\n",
        " - Start with a few well-performing models’ ensemble\n",
        " - Loop through each other model in a library and add to current ensemble\n",
        " - Determine best performing ensemble configuration\n",
        " - Repeat until metric converged\n",
        "- If you are using linear regression as the meta model, make sure you have **diverse/uncorrelated** first layer models\n",
        "\n",
        "- During each loop iteration it is wise to consider only a subset of library models, which could work as a regularization for model selection.\n",
        "\n",
        "- Repeating procedure few times and bagging results reduces the possibility of overfitting by doing model selection.\n",
        "\n",
        "- R users can use the `caretStack` function from the [caretEnsemble](https://github.com/zachmayer/caretEnsemble) package directly. A nice tutorial [here](https://machinelearningmastery.com/machine-learning-ensembles-with-r/).\n",
        "\n",
        "- The `stackedEnsemble()` function from the [H2o package](https://h2o-release.s3.amazonaws.com/h2o/rel-ueno/2/docs-website/h2o-docs/data-science/stacked-ensembles.html) is also a good choice out there. But the downside is it only takes h2o model as input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Sg4aXAsHgox"
      },
      "source": [
        "## Success formula (personal opinion)\n",
        "\n",
        "50% - feature engineering\n",
        "\n",
        "30% - model diversity\n",
        "\n",
        "10% - luck\n",
        "\n",
        "10% - proper ensembling\n",
        " - Voting\n",
        " - Averaging\n",
        " - Stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kndWr2WloYcI"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}